先是看了一遍b站新兴up主 statquest 的 从RNN--LSTM--self-attention到transformer的视频。
statquest其实前几年就在油管上发布过机器学习和深度学习的视频，只不过今年b站才有了搬运视频。
and 我觉得讲的比较通俗易懂，所以先看了一遍了解一下。

接着看了李宏毅的self-attention和transformer的视频（嗯，讲的也很清楚，台湾腔和闽南语让人熟悉。）
以上这部分用了三四天的零散时间。

然后开始看太阳花的视频，以及他分享的代码。
视频还好，代码是真的………（直到11.15，也就是昨天才跑起来）。
各种报错，因为一开始我连路径怎么上传都母鸡。
后来路径都配好了。
还是报错，
![0483c68b100ca7c412effe83cd96ba2.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411162216692.png)
于是不明所以的我去买了算力云，试图看看好一点的配置能不能解决这个问题，结果是没有成功。


最后在hjj组长的提示下，试了把batch_size设为0，据说这样便只在主线程跑了。然后成功运行了。

以及第二天hjj组长发现，把worker的数量设为0，即使batch_size不为0，也能跑得起来。

```
与ai的QA

Q：目前只有两种情况能运行成功，一次是nw=0，batch=8；还有一次是nw不为0，batch=1；nw和batch有什么关系，为什么会出现那些情况？


A：根据你描述的两种成功运行的情况，我们可以分析 `nw`（工作线程数）和 `batch size`（批处理大小）之间的关系，以及为什么只会出现这两种情况。

### 成功运行的情况：

1. **nw=0，batch=8**：
    
    - **设置说明**：设置 `nw=0` 意味着所有的数据加载和预处理过程都发生在主线程中，采用顺序执行的方式。每次处理的样本数量是8。
    - **成功原因**：
        - **简单性**：没有多个线程操作数据，避免了多线程引起的竞争状态和数据不一致的问题，因此成功运行的概率较高。
        - **批处理效率**：较大的 `batch size` 允许GPU更高效地进行并行计算，计算效率相对较高，尽管数据加载速度可能较慢。
2. **nw不为0，batch=1**：
    
    - **设置说明**：在这种情况下，启用了多个工作线程进行数据加载，但每次只处理一个样本。
    - **成功原因**：
        - **并行性**：多个线程可以加快数据的加载速度，尽管每个线程仅处理一个样本。这种设置在处理较小数据集或简单数据加载逻辑时能够顺利运行。
        - **低内存消耗**：批处理大小为1减轻了内存压力，降低了出错的风险。

### nw 和 batch size 的关系及可能出现问题的原因：

1. **数据量与加载效率**：
    
    - 当 `batch size` 较大（如`batch=8`）时，需要确保数据加载的效率足够高，以免GPU空闲等待数据。如果使用多个工作线程的数据加载严重依赖于数据的访问速度，如果数据加载不够快，可能导致出错。
    - `batch=1` 则意味着较低的计算度，多个线程可以充分利用并行性来处理数据，从而成功运行。
2. **多线程时的数据一致性**：
    
    - 使用多个工作线程时，若数据加载存在问题（如索引越界、数据损坏等），错误的发生率可能增加。而 `nw=0` 状态下，由于在主线程中顺序执行，可以避免这类问题。
3. **GPU利用率与内存管理**：
    
    - 在高负载情况下（如较大的 `batch size`），需要合理配置 `nw`，以避免GPU内存不足或溢出的问题。你的两种情况可能表明，只有这两种配置能够在现有的数据和硬件条件下顺利运行。

### 总结：

这两种成功情况可能表明数据处理的稳定性和资源使用的平衡。合理调整 `nw`和`batch size` 的组合，同时保证数据的一致性，将有助于提高模型训练的成功率和效率。如果你继续遇到问题，建议检查数据集的大小和质量，确保数据在并行处理时不会出现错误。
```

最后得出结论：是现有设备的问题。

代码问题解决之后，就从网上找图predict了几十张图片。一开始只用了base16_in21k权重集进行测试。清晰而且人眼可分辨的花朵图片肯定能够准确预测，而且预测出来概率基本都是0.9+。

##### 第一类
而一些人眼比较难辨别的图片，也是可以识别出来的，比如特地模糊，扭曲，马赛克的图片。当然极度扭曲的图片会“面目全非”（比如第一张，原图是郁金香，但预测出来时rose）。
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161242258.png)
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161240557.png)
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161250122.png)

![Pasted image 20241116121428](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161223090.png)

##### 第二类
同时，一些人眼没办法识别（至少我没办法识别）的图片，ai也能识别出来。
![Pasted image 20241116121934](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161223100.png)
##### 第三类
一些简笔画的图片也是能识别出来的。（概率有高有低）
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161303068.png)
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161230258.png)


##### 第四类
一张图片中不止一种花，识别效率参差不齐。（测的数据量比较小，但是姑且让我武断，vit比较适合ViT通常用于单一类别的分类任务）
比如以下第一张图（base16），sunflower和daisy，daisy只有0.2，而sunflower有0.5。
甚至于以下第二张图（large16），sunflower概率高达0.9+。
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161354811.png)
![47f366153ce99081f9915e72eb4410a3.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411162247242.png)
##### 第六类
无关项占比过大导致判断出错。
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161316091.png)

而当把无关项裁剪掉之后，预测结果就正常了。
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202411161318988.png)
可以得出，


and，现在vit的代码我也只是了解整个vit的结构如何表示，但是一些细节仍还没来得及看。
嗯，先总结到这吧。
