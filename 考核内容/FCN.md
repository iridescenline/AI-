## CNN进行语义分割 的优劣点

CNN的强大之处在于它的多层结构能够自动学习特征，并且可以学到多个层次的特征：较浅的卷积层感知域小，能学到一些局部的特征，而较深的卷积层感知域大，能学到一些更加抽象的特征。这些抽象特征对物体的大小，位置和方向等敏感度更低，有助于图像内容的分类。与此同时，抽象特征丢失了一些物体的细节，不能很好地给出物体地具体轮廓，指出每个像素具体属于哪个物体，因此难以做到精确的分割。

**传统的基于CNN的分割方法**：为了对一个像素分类，使用该像素周围的一个图像块作为CNN的输入用于训练和预测。这种方法有几个缺点：一是存储开销很大。例如对每个像素使用的图像块的大小为15x15，然后不断滑动窗口，每次滑动的窗口给CNN进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。二是计算效率低下。相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。三是像素块大小的限制了感知区域的大小。通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。

## FCN

### FCN的架构

![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202410161909960.png)
composed by three parts: 
part1:卷积化 encoder
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202410161912122.png)
最后不适用CNN采用的全连接层，用的是输出为1 * 1 * 通道数的卷积层。

part2：反卷积化/转置卷积 decoder
转置卷积的卷积核大小也是可以学习的，可以先利用插值进行初始化，然后再通过反向传播来进行学习。
把图像大小放大回原始图像的大小。

part3：跳远连接 skip connection
把7x7的图像放大到14x14，（在encoder过程中，把图片缩小会损失信息，而这些损失的信息在decoder过程中，没办法再加载回来），这时候使用跳远连接把encoder部分相同维度的图像与放大后的14x14图像相加，能够减少信息的损失。
![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202410161918179.png)


![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202410161929052.png)

![image.png](https://erin-53347-1330131220.cos.ap-guangzhou.myqcloud.com/202410161934579.png)





### FCN的作用总结
FCN（全卷积网络）相比于普通CNN在图像语义分割任务中有几个显著的优势：

1. **像素级分类**（pixel-wise semantic segmentation）：FCN使用了转置卷积，将经过卷积层的图像解码回原始的分辨率。
 可以直接输出与输入图像相同尺寸的特征图，实现像素级的分类（识别每一个像素所在的类），而普通CNN通常只能提供图像级的分类结果。
    
2. **空间信息保持**：由于FCN的全卷积架构，网络能够保持输入图像的空间信息，避免了全连接层引入的位置信息丢失。
    
3. **灵活性**：之前学的VGG和ResNet都只能处理固定大小的输入图像（因为它们最后都使用到了全连接层fully connected layer)，而FCN (fully convolutional network) 可以处理任意尺寸的输入图像，这使得它在不同应用场景中具有更大的灵活性。

4. **上下文信息**：FCN通过使用多个卷积层和跳跃连接，能够有效捕捉上下文信息，从而改善分割的精细度和准确性。
    
5. **计算效率**：FCN避免了全连接层的高计算成本，尤其是在处理大尺寸输入时，使用卷积层的计算效率更高。


### 相关内容
[[转置卷积]]
[[图像插值]]